# 数学前置：

尝试证明公理，三天解决不了看答案锻炼数学思维。

不理解数学，不可能理解AI模型。

把数学当做语言：不管它的意思，严格按照要求 → 我们主要讲方法 

数学真正的学法是以**证明**为目的。



## **数学真正的思考方式**

Frame and Hypotheses  框架和假设

Elements and Relationships  要素与关系

Patterns  模式

Intuition 直觉

Retrospect and Empathetic  回顾与共情（我当初为什么没有这样想？）

Bucket(In/Out/New)  ：木桶原理 寻找定理的假设依据  自己的方法论（可以闭环）

 Strategic minds 战略思维

最基本前提：理解/掌握各种角度



## **数学理论的主要内容**

机器学习的各种角度和建模流程 

概率论和统计学基础概念复习 

极大似然体系和 EM 算法 

贝叶斯体系和 Variational Bayes 算法 

矩阵代数：基本概念复习和 Tensor 求导

证明的过程：把已知的公式写出来，寻找和需要证明的公式的联系

log单变

BCE：交叉熵

HMM：需要背诵推导过程

贝叶斯：用后验更新先验

似然函数定义：θ是固定的，但是在贝叶斯里，θ 是随机的，所以写成 P(x|θ) 但还是似然函数。



# 机器学习概念

## 机器学习的最终目的：

效果好，即准确性高 。为了达到最终目的，必须从不同角度考虑。



## 函数逼近的视角：

这是最简单的是视角，目标：给定 X 预测 y 。

假设：存在真实的 y = f_0(X) 如果知道 f_0，那么就不需要做任工作,但是我们不知道，所以需要逼近。
$$
观察~\{X_i,y_i;i \epsilon J~\}\\
假设f \epsilon F\\
目标：给定一个损失函数c,最小化\sum_ic(f(X_i),y_i)
这个估计可以被称之为ˆf
$$
最理想状况 ˆf = f_0；事实上（可能）不可能\\
不可能原因（一）：没有所有的 X 和 y 的组合\\
不可能原因（二）：f_0 ∈ F/\\
不可能原因（三）：求解 ˆf 时候有困难\\
但是基本启示是：要找到一个足够大的 F 使它包含 f_0, 并且要求 F 应
该足够小使得求解比较容易 → 自相矛盾\\最理想状况 ˆf = f_0；事实上（可能）不可能。

## 随机的世界：

本质上来说，世界上是随机的。

随机的来源： 缺乏信息 → 最主要问题，在表格化数据中最为明显 

测量误差 → 大部分信息都有误差:比如说年龄 800 岁，收入 400 万亿

模型误差 → 假设模型形式和现实的差别

估计误差 → 得到模型过程中造成的误差

优化误差 → 求解过程中的误差

评估误差 → 评估本身也存在误差



### 插值：

插值是离散函数逼近的重要方法，利用它可通过函数在有限个点处的取值状况，估算出函数在其他点处的近似值。

插值：用来填充图像变换时像素之间的空隙。



### 统计学根本区别于函数逼近的原因:

函数逼近：y = f0(X) 

统计学 :y = f_0(X) + ϵ



### Bias与Variance

Bias偏差：话说得很详细，但是很不准

eg: 北京明天下午两点四十分会发生里氏 2.6 级地震。

Variance方差：含糊其词，但是很准

eg: 在这个世界上有一天会发生地震。

**往往存在 Bias 和 Variance 的权衡（但这不是全部，它本身的数学理论只是针对回归的）**

 Bias 大：过拟合 ，承受过多损失

Variance 大：欠拟合

测量误差往往难以处理，是数据预处理一个重要部分。



### 模型假设：

假设背景：存在一个上帝知道的真实的模型，但他不知道部分误差，所以模型一定会有损失。

​	但就该损失函数而言，这个真实的模型一定是预测最好的。

现实情况：因为我们不知道真实的模型，所以只能采用一些模型来逼近，如果模型跟真实模型很近，则效果应该是最好的。

​	一般情况下不知道真实模型，只能选择一般的模型 → 估计方差大



### 估计误差：

即使对于同样的模型或问题，也有不同办法得到模型的参数。

​	极大似然估计和贝叶斯估计

​	增强学习中的 Q-learning 和 Policy Gradient

好的方法可以减少其中误差。



### 估计问题：

求解的过程，就是迭代的过程。

迭代是否会收敛是一个很大的问题。

在神经网络中尤其明显，但在传统模型中也存在。



### 评估问题：

因为不知道真实的损失函数（除非有无限多的测试样本），所以必须评估。

评估的越多，训练样本就越少 → 出现了交叉验证的概念

注意避免**不公平的评估**



### 评估误区

只用训练集 → 不公平

无数次的测试训练集 → 不可以（否则猜就可以了）

建模数据和实际场景不同：在 2019 年建模预测 2020 年上半年旅游业情况

重要原则：一定要看评估本身的误差多大，然后决定做法是否有提升。

重要提示：越是误差小的领域，需要概率角度越多。

误差大的领域，概率角度可能不能帮上太多忙，更应该找可以优化的地方。



## 理论的例外：预训练的存在

从概率理论上来说，预训练不应该有任何帮助：

**预训练和当前任务无关而且模型表达力没有变。**

预训练是深度学习最重要发明之一 。

现实：预测词语表示了对语义的理解，所以对预测情感有帮助。

从优化的角度来说：有利于优化。

其他角度：

很多问题要 case-by-case 分析

重点：从不同角度出发（数学思维）

从不同角度看同一个问题：其他角度的进展也可以帮助解决这个问题



## 总结

从不同角度出发（数学思维） 

从不同角度看同一个问题：其他角度的进展也可以帮助解决这个问题。



# 概率论

概率论是描述随机的语言，分为朴素概率论和公理性概率论。

## 基础知识

#### 一维离散PDF：

一维离散可以直接讨论概率 

 一维离散可以假设概率取值只是整数
$$
P(X ≤ x) = \sum_{i≤x}^{} p(X = i), 或者用更标准的写法 P(X ≤ t) = \sum_{i≤t}^{}P(x）
$$
#### 二维离散CDF：

连续意味着可能性至少不是有限的，**还是可以定义 P(X ≤ x)但不能定义是定义 p(x)**

#### 连续变量：

连续意味着可能性至少不是有限的

还是可以定义 P(X ≤ x) 但是定义 p(x) 的时候就有问题

#### **PDF与CDF：**

在给定一个连续变量时，只能定义
$$
P(X ≤ m) = \int_{-\infty}^{m}p(x)dx
$$
虽然离散和连续的定义有所不同，但是积分本身就是一种非常复杂的加法
$$
F_X(t) := P(X ≤ t) 就是Cumulative Distribution Function（累积分布函数）
$$
p(x) 就是Probability Density Function(概率密度函数)，不是概率值

#### 多维情况下：

以二维为例：
$$
P(X ≤ m, Y ≤ n) = \int_{-\infty}^{m}\int_{-\infty}^{n}p(x)dxdy
$$
对于边际分布 p(x) = ∫ p(x, y)dy：只关心x的趋势所以对y积分

条件概率 p(x|y) = p(x, y) / p(y)



## 数学期望

给定一个概率密度函数p(x),再给定一个函数f(x)，定义数学期望(Expectation)为：
$$
E_p[f(x)] = \int f(x)p(x)dx
$$

条件数学期望:

给定一个条件概率密度函数 p(x|y), 再给定一个函数 f(x)，定义其的条件数学期望（Conditional Expectation）为：
$$
E_p[f(X)|Y=y]:=\int f(x)p(x|y)dx
$$

## 正态分布

若随机变量X服从一个数学期望为μ、方差为σ^2的正态分布，记为N(μ，σ^2)。

其概率密度函数为正态分布的期望值μ决定了其位置，其标准差σ决定了分布的幅度，当μ = 0,σ = 1时的正态分布是标准正态分布。
$$
若X ~\~{}N（\mu,\sigma^2),Y=\frac{X-\mu}{\sigma}\~{N(0,1)}
$$

一维正态分布

若随机变量X服从一个位置参数为 µ、尺度参数为σ的概率分布，且其概率密度函数为：
$$
f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x,\mu)^2}{2\sigma^2}}
$$
则这个随机变量就称为正态随机变量，正态随机变量服从的分布就称为正态分布，记作X~(μ,σ^2),读作X服从N(μ,σ^2) ，或X服从正态分布。



## 条件概率

$$
P(A|B) = \frac{P(AB)}{P(B)}
$$

## 贝叶斯公式

$$
P(A|B) = \frac{P(B|A)P(B)}{P(B)}\\
P(A_i|B)=\sum_j\frac{P(B|A_i)P(A_i)}{P(B|A_j)P(A_j)}
$$

在贝叶斯法则中，每个名词都有约定俗成的名称：
P(A)是A的先验概率或边缘概率。之所以称为"先验"是因为它不考虑任何B方面的因素。
**P(A|B)**是已知B发生后A的条件概率，也由于得自B的取值而被称作**A的后验概率**。
P(B|A)是已知A发生后B的条件概率，也由于得自A的取值而被称作B的后验概率。
**P(B)是B的先验概率或边缘概率，也作标准化常量（normalized constant）。**

### **手推贝叶斯公式**

$$
p(y|x) = \frac{p(y)p(x|y)}{∫ p(x|y)p(y)dy}
$$

前置条件：
$$
p(x|y)=p(x,y)/p(y)
$$

$$
p(x)=\int p(x,y)dy
$$

推导过程：
$$
\because p(x|y)=p(x,y)/p(y),
$$

$$
\therefore p(y|x) =p(x,y)/p(x),p(x,y)=p(y)p(x|y)
$$

$$
\therefore p(y|x)=\frac{p(y)p(x|y)}{p(x)}
$$

$$
\because p(x)=\int p(x,y)dy，结合p(x,y)=p(y)p(x|y)
$$

$$
\therefore p(x)=\int p(x|y)p(y)dy
$$

证毕。

## **重点部分**：

$$
Multinomial：P(X = xi) = pi
$$

#### **正态分布：**

$$
p(x) = {\frac{1}{ σ\sqrt{2π}} }{e(^-{\frac{(x-\mu)^2}{2\sigma^2}})}\\
或者\\
p(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{{-\frac{1}{2}}({\frac{x-\mu}{\sigma})^2}}
$$


其中 µ 是 σ 是参数。常常写成 X ∼ N(µ, σ^2 )

当μ=0，σ=1时，正态分布就成了标准正态分布：
$$
f(x)={\frac{1}{ \sqrt{2π}} }{e^{ -\frac{x^2}{2} }}
$$

#### **极大似然估计**:

考虑最简单的情况，即掷一个不公平的硬币：

每一个硬币向上的概率为p(xi)，用yi = 1记载硬币向上 

就此得到硬币向下的概率为 1 − p(xi), 用 yi = 0表示 

整体观测到目前情况的概率为：
$$
p(x_i) y_i × (1 − p(x_i))(1−y_i)，这就是似然函数
$$
取个 log，这就是对数似然函数： 
$$
y_ilog(p(x_i)) + (1 − y_i)log(1 − p(x_i))
$$
#### 极大似然函数的基本思想：

**找到使目前似然函数最大的那个观测**

**或者由于对数变换是单调变化，找到负的对数似然函数最小的那个。**



只抛一次硬币，当然没有任何做推断的价值

现在假设抛 N 次硬币，得到观测 {x_i  , yi ; i ≤ N} 

继续假定每次抛硬币的结果不影响下一次抛硬币的概率分布，即观测独立

则似然函数为 
$$
∏ _i p(x_i)^{y_i}(1 − p(x_i))^{(1−y_i)}
$$
连乘带来的问题：因为如果连乘一个 0 到 1 之间的数，得到的乘积会越来越小，特别小的时候，电脑就会出现数值问题（比如说10 的负十万次方）

如何解决数值问题?

取个 log 即可：log(xy) = log(x) + log(y)。 

则负的对数似然函数为：
$$
− ∑ _i (y_i log(p(x_i)) + (1 − yi)log(1 − p(x_i))) 这就是 Binary Cross Entropy交叉熵
$$
**交叉熵是极大似然估计的一个特例。**

接下来考虑p(x_i)长什么样？

首先，0<=p(xi)<=1

一个常见选择:
$$
p(xi) = \frac{1}{1+e^{-f(x_i)}}
$$

$$
如果 f(x_i) = ∑ _k β_kx_i , 其中 β_k 为未知参数（需要求解），则得到了逻辑回归的数学表达形式
$$

【注】：这种 f 的函数形式被称之为线性函数，近似于多个线性函数组合 的函数是最重要的一类函数形式。



现在假设有 yi，服从期望为 f(x_i) 且方差为 1 的正态分布。（必须假定其概率分布）

也就是说 
$$
p(y_i) = \frac{1}{\sqrt{2π}} e^{\frac{(−(y_i − f(x_i))^2}{2})}
$$
推导其对应的对数似然函数：
$$
-\sum _i{p(y_i)} = {-\sum _i \frac{(-y_i-f(x_i))^2}{2}} + K
$$
其中 K 是一个跟 f 无关的常数，所以这里最小化的距离是 
$$
∑ _i (y_i − f(x_i))^2,这就是最小二乘法。
$$

## 分类与回归

第一种情况，称之为二分类分类问题。对应多分类问题也可以进行对应推导。 

第二种情况，称之为回归问题。

大部分机器学习工程师假设世界上只存在这两种问题。但是事实上，即使在监督学习框架下其他问题也很多。

**某银行小微快贷额度测算问题 **

目标：小企业贷款额度确定 

考虑的方向

​	1.违规可能性：要把风险控制在一定范围内 

​	2.需求：对贷款需求越高的企业应该给更多贷款 

​	第一个问题可以作为分类问题解决 

​	第二个问题不好解决

基本思想：

**虽然观测不到企业的真实需求，但可以假设存在一个真实需求。**

我们知道实际放款额和实际使用金额，所以存在两种情况： 

放款额度 > 实际使用金额，可以假定实际需求即为实际使用金额

放款额度 = 实际使用金额，虽然不知道实际需求，但是知道实际需求一定大于等于放款额度

模型的基本思路：
$$
假设真实需求为 y^∗_ i,观测不到
$$

$$
进一步假设 y^∗_i = f(x_i) + ϵ_i，且 ϵ_i 为正态分布
$$

$$
建行所给真实的额度假设为 y_i
$$

$$
当发生截断时，其似然函数为 P(y^∗ _i ≥ y_i)
$$

$$
当不发生截断时，其似然函数为 p(y_i)
$$

两者结合，即可以得到估计方式。

[注] 截断：放款额度 = 实际使用金额



## 极大似然估计

通常情况下，在极大似然框架中如果容易推导出对数似然函数，那么求解将会非常容易。

但是如果存在隐变量，则推导变得非常困难。

在一些情况下，EM 算法是解决隐变量问题的一个非常通用的框架 (现实情况少见) 

但部分大厂面试喜欢要求推导 HMM 的估计方式。

### EM算法

考虑以下关系：用 l(θ; X) 表示对数似然函数，则 ：
$$
I(\theta,X) = log p_\theta(X)
$$

$$
=log \int p_\theta(X,y)dy
$$

$$
=log \int \frac{p_\theta(X,y)}{p^*_\theta(y|X)}p^*_\theta(y|X)dy
$$

$$
\geq log \int (p_\theta(X,y))p^*_\theta(y|X)dy - \int log(p^*_\theta(y|X))p^*_\theta(y|X)dy
$$

$$
=E_\theta^*[log p_\theta(X,y)|X]-E_\theta^*[log p_\theta^*(X,y)|X]
$$

[注]
$$
y是一个隐变量，θ^*是当前的估计，目标是通过迭代的方法找到下一步的估计θ。
$$

$$
换句话说，因为E_\theta^*[log p_\theta^*(y|X)|x]跟 θ 没有关系，所以可以忽略。
$$

$$
定义 Q(θ, θ^*) = E_\theta^*[log p_\theta(X,y)|X]，则 EM 算法可以定义为；
$$

$$
计算 Q(θ, θ^*); 
$$

$$
最大化 θ := argmax_θ^′Q(θ^′ , θ^*)
$$

### 隐马尔可夫链（默写）

HMM 算法的估计方法称之为 Baum-Welch 算法。
$$
假设对于每一个观测 d 可以观测到~\{ X^{(d)}_t , 1 ≤ t ≤ T~\}。
$$

$$
它的概率分布取决于隐变量z^{(d)}_t。并且该变量服从马尔可夫性质。
$$

$$
因此，如果知道 t − 1 的信息，就不需要知道更早的信息，就可以得到 z^{(d)}_t 的
概率分布。
$$

$$
假设 X’_s 和 z’_s 都只能取有限多个值
$$

我们有：
$$
P(z,\chi;\theta)=\prod_{d=1}^{D} (\pi_{{z_1}^{(d)}} B_{z_1^{(d)}} (x_1^{(d)})
\prod_{t=2}^T A_{{z_{t-1}^{(d)}}{z_{t}^{(d)}}} B_{z_{t}^{(d)}} (x_t^{(d)}))\\
(d) 上标表示观测 d;\\
\pi_{{z_1}^{(d)}}为初始分布;\\
A_{{z_{t-1}^{(d)}}{z_{t}^{(d)}}}为转移概率;\\
B_{z_{t}^{(d)}}(X_t^{(d)})为发射概率。
$$

<img src="https://avikdas.com/assets/images/2019-06-24-dynamic-programming-for-machine-learning-hidden-markov-models/hmm-bare.png" alt="Dynamic programming for machine learning: Hidden Markov Models" style="zoom: 33%;" />



对上式取 log 之后:
$$
logP(z,\chi;\theta) = \sum^{D}_{d=1}[log\pi_{{z_1}^{(d)}}+
\sum^{T}_{t=2}logA_{{z_{t-1}^{(d)}}{z_{t}^{(d)}}}+
\sum^{T}_{t=1}logB_{z_1^{(d)}}(x_t^{(d)})

]
$$
放到 Q 函数中，假设目前的参数 θ^s：
$$
Q (θ, θ^s) = \sum_{z\epsilon Z} \sum_{d=1}^{D} log \pi_{{z}_{1}^{(d)}} P(z,\chi;\theta^s)\\
+ \sum_{z\epsilon Z} \sum_{d=1}^{D} \sum_{t=2}^{T}log A_{{z_{t-1}^{(d)}}{z_{t}^{(d)}}} P(z,\chi;\theta^s)\\
+\sum_{z\epsilon Z} \sum_{d=1}^{D} \sum_{t=1}^{T}logB_{z_1^{(d)}}(x_t^{(d)}) P(z,\chi;\theta^s)\\
$$
加上拉格朗日乘子：
$$
L^\^(\theta,\theta^s)-\lambda_\pi(\sum^{M}_{i=1}\pi_i-1)\\
-\sum^{M}_{i=1}\lambda_{A_i}(\sum^{M}_{j=1}A_{ij}-1)\\
-\sum^{M}_{i=1}\lambda_{B_i}(\sum^{N}_{j=1}B_i(j)-1)
$$
求解Π_i
$$
\frac{\partial L\^(\theta,\theta^s)}{\partial \pi_i} = 
\frac{\partial}{\partial \pi_i}( \sum_{z\epsilon Z} \sum_{d=1}^{D} log \pi_{{z}_{1}^{(d)}} P(z,\chi;\theta^s) )-\lambda_\pi=0\\

=\frac{\partial}{\partial \pi_i}( \sum_{j=1}^{M} \sum_{d=1}^{D} 
log \pi_{{j}} P(z_{1}^{(d)}=j,\chi;\theta^s) )-\lambda_\pi=0\\

=\sum_{d=1}^{D}\frac{P(z_{1}^{(d)}=i,\chi;\theta^s) )}{\pi_i}-\lambda_\pi=0
$$

$$
\frac{\partial L^\^(\theta,\theta^s)}{\partial \lambda_\pi} = 
-(\sum^{M}_{i=1}\pi_i - 1)=0
$$

求解：
$$
\pi_i = \frac{\sum^{D}_{d=1}P(z_1^{(d)}=i,\chi;\theta^s)}{\sum^{M}_{j=1}\sum^{D}_{d=1}P(z_1^{(d)}=j,\chi;\theta^s)}\\
=\frac{\sum^{D}_{d=1}P(z_1^{(d)}=i,\chi;\theta^s)}{\sum^{D}_{d=1}\sum^{M}_{j=1}P(z_1^{(d)}=j,\chi;\theta^s)}\\

=\frac{\sum^{D}_{d=1}P(z_1^{(d)}=i,\chi;\theta^s)}{\sum^{D}_{d=1}\sum P(\chi;\theta^s)}\\

=\frac{\sum^{D}_{d=1}P(z_1^{(d)}=i,\chi;\theta^s)}{DP(\chi;\theta^s)}\\
=\frac{\sum^{D}_{d=1}P(\chi;\theta^s)P(z_1^{(d)}=i|\chi;\theta^s)}{DP(\chi;\theta^s)}\\
=\frac{1}{D}\sum^{D}_{d=1}P(z_1^{(d)}=i|\chi;\theta^s)\\
=\frac{1}{D}\sum^{D}_{d=1}P(z_1^{(d)}=i|X^{(d)};\theta^s)
$$
采用类似的方法：
$$
A_{ij}=\frac{\sum^{D}_{d=1}\sum^{T}_{t=2}P(z_{t-1}^{(d)}=i,z_{t}^{(d)}=j,\chi;\theta^s)}

{\sum _{j=1}^{M} \sum^{D}_{d=1}\sum^{T}_{t=2}P(z_{t-1}^{(d)}=i,z_{t}^{(d)}=j,\chi;\theta^s)}\\

=\frac{\sum^{D}_{d=1}\sum^{T}_{t=2}P(z_{t-1}^{(d)}=i,z_{t}^{(d)}=j,\chi;\theta^s)}

{\sum^{D}_{d=1}\sum^{T}_{t=2}P(z_{t-1}^{(d)}=i,\chi;\theta^s)}\\

=\frac{\sum^{D}_{d=1}\sum^{T}_{t=2}P(\chi;\theta^s)P(z_{t-1}^{(d)}=i,z_t^{(d)}=j|\chi;\theta^s)}

{\sum^{D}_{d=1}\sum^{T}_{t=2}P(\chi;\theta^s)P(z_{t-1}^{(d)}=i|\chi;\theta^s)}\\

=\frac{\sum^{D}_{d=1}\sum^{T}_{t=2}P(z_{t-1}^{(d)}=i,z_t^{(d)}=j|X^{(d)};\theta^s)}

{\sum^{D}_{d=1}\sum^{T}_{t=2}P(z_{t-1}^{(d)}=i|X^{(d)};\theta^s)}
$$
同理：
$$
B_i(j) = \frac{\sum^{D}_{d=1}\sum^{T}_{t=1}P(z_{t}^{(d)}=i,\chi;\theta^s)I(x^{(d)}_t=j)}
{\sum^{N}_{j=1}\sum^{D}_{d=1}\sum^{T}_{t=1}P(z_{t}^{(d)}=i,\chi;\theta^s)I(x^{(d)}_t=j)}\\
=\frac{\sum^{D}_{d=1}\sum^{T}_{t=1}P(z_{t}^{(d)}=i,\chi;\theta^s)I(x^{(d)}_t=j)}
{\sum^{D}_{d=1}\sum^{T}_{t=1}P(z_{t}^{(d)}=i,\chi;\theta^s)}\\

=\frac{\sum^{D}_{d=1}\sum^{T}_{t=1}P(z_{t}^{(d)}=i|X^{(d)};\theta^s)I(x^{(d)}_t=j)}
{\sum^{D}_{d=1}\sum^{T}_{t=1}P(z_{t}^{(d)}=i,|X^{(d)};\theta^s)}
$$

$$
思考： 为什么要推导P(z_{t-1}^{(d)}=i,z_t^{(d)}=j|X^{(d)};\theta^s)和P(z_t^{(d)}=i|X^{(d)};\theta^s)
$$

答：这两者可以用动态规划很容易求解。

**难点**

可以动态求解有效
动态求解这件事情不可能一眼看出来，甚至我们在开始推导的时候也不可能考虑到动态求解的问题。
在这个推导过程中，如果不知道我们目标是推出这两个量的表达式，则可能会在几百个可能性当中折腾很久。

## 贝叶斯估计和变分贝叶斯

在上述所有的模型中，均假设有所谓的真实参数或模型，目的只是推导这个真实的模型。

贝叶斯学派的视角不同： 假设参数是 θ，将会对其有一个 prior先验，表示为 p(θ)，换句话说θ本身就是随机。

现在得到了观测：X，**目标是得到 posterior后验：p(θ|X)** 即在有了观测X后更新先验结果θ。

根据贝叶斯公式，有：
$$
p(\theta|X) = \frac{p(X|\theta)p(\theta)}{\int p(X|\theta)p(\theta)d\theta}
$$
【任务】假设 µ ∼ N(0, 1), X|µ ∼ N(µ, 1)，推导 µ 的 posterior即p(µ|X)：
$$
\because 无参数 \theta,\therefore 对\theta的积分为1，p(\mu|X)∝(正比)p(X|\mu)p(\mu)
$$

$$
∝e^{(\frac{-\mu^2}{2})}e^{\frac{-\sum_i(X_i-\mu)^2}{2}}
$$

$$
与\mu无关的全部舍弃得：
∝e^{(-(\frac {N+1}{2}\mu^2)-\mu \sum_i X_i)}
$$

$$
∝e^{(-(\mu^2-\frac {2\sum_iX_i}{N+1}\mu)/(\frac{2}{N+1})}
$$

$$
∝e^{[(\mu-\frac{\sum_iX_i}{N+1})^2/\frac{2}{N+1}]}
$$

$$
\mu|X - N(\frac{\sum_iX_i}{N+1},\frac{1}{(N+1)^2})。
因此，posterior也是正态分布,这称之为Conjugate Priors共轭先验
$$

贝叶斯方法的好处和坏处

 好处:很方便的处理隐变量;可以对不确定性进行估计

坏处：计算麻烦 → 就目前深度学习应用来说，最方便的是变分法。



### 手推证明

$$
log P(X) − D[Q(z)||P(z|X)] = E_{z∼Q}[log P(X | z)] − D[Q(z)||P(z)]
其中 D 为 KL-divergence
$$

KL-divergence:

Kullback-Leibler散度D_kL（也称为相对熵）是一种概率分布与第二种参考概率分布有何不同的度量。
$$
\because D_{kL}(P||Q) = \int p(x)log(\frac{p(x)}{q(x)})dx\\
等式左边：\\
logP(X)-\int q(z)log q(z)+\int q(z)logp(z|X)dz\\
等式右边：\\
\int q(z)logP(X|z)dz - \int q(z)logq(z)+ \int q(z)logp(z)dz\\
我们只需计算：
log P(X)+\int q(z)logP(z|X)dz - \int q(z)logP(X|z)dz-
\int q(z)logp(z|X)dz\\
=logP(X)+ \int q(z)logp(z|X)dz-\int q(z)logP(X|z)dz-\int q(z)log(\frac{p(z|X)p(X)}{p(X|z)dz})
$$
展开会发现原式=0。









