真实的建模过程



## 传统模型评估方法

在传统模型评估方法中，数据集将会被分为三个部分：训练集、验证集 （开发集）和测试集

训练集目的：在给定超参数的情况下，对模型参数估计（训练） 

验证集目的：选择超参数 

测试集目的：测试最终选择的模型的真实表现



为什么需要验证集？

可以考虑 L1 正则化的结果

对于训练集来说，最好的结果一定是 L1 正则化的惩罚系数为 0 的情况, 为什么？

在得到了训练集上根据某个正则化惩罚系数的情况下，在验证集上可以得到关于模型泛化性的一个相对客观的评价。



为什么不能用测试集替代验证集 ？

如果手头有测试集的结果，则从技术上而言，可以用测试集替代验证集的作用,但是这样做是非常危险的。

虽然没有在测试集上直接拟合模型，但是通过测试非常多的超参数 也近似的达到了效果

一个更极端的例子：

如果加入测试集当中的只有正负样本，我们第一次将预测都设定为负样本，从第二次测试开始，我们每一次只改变其中一 个测试。只要我们有足够多次的评估，我们就可以把正确的值推算出来。

**所以如果过多的在测试集上评价，则会高估测试集的效果。**



评估方法的问题

如果有极多的数据，那么上述方法还一般可行。但是通常情况下，可以得到的整体数据量是非常有限的。

这种情况下，如果还要用之前的方法就会导致： 

​		训练集的数据量不够，导致精度不够。

​		验证集的数据量不够，导致验证准确性不强。



## k-Fold交叉验证

![“k-fold”的图片搜索结果](data:image/png;base64,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)

关于 k-fold 的选择

一般来说，k-fold 随机选取就可以。

但是在一些情况下，k-fold 和 Test 集合在随机选取的情况下，仍然可能有很大的差别。

这种情况有可能是几种情况造成的：

​		k-fold 本身的随机性

​		训练（验证）集和测试集本身的差异 

一般来说希望的是：**尽可能保证 k-fold 结果和测试集一致。**



## 分布匹配的问题 

一般来说，我们希望训练、验证和测试集都来自于一个分布，但是这种假设经常被打破。

比如对于时间序列来说，如果我们用 2019 年的经济数据来预测 2020 年经济数据，则大概率不会得到很好的结果.

这种问题没有通用的良好解决方法，一般来说只有两种可能性：

​		尽可能保证样本具有足够代表性：“北京样本收入估计全国” →“全国抽样估计全国” 

​		尽可能保证模型的多样性：模型集成



## 模型集成基本思路

以二分类为例:

由于每个模型都有一定的长处和短处，所以尽可能用多个模型的共同结果来进行预测

最简单的模型集成：将一个数据集 k-fold 之后直接采用预测概率的平均



Q：

传统方法建议使用 k-fold 选择超参数，然后再使用同样的参数对所有的训练集进行训练并预测 → 这样的训练有什么问题？



核心问题（之一）在于超参数的选择和观测数量有很大关系。

如果我们改变观测数量，实际上也改变了最佳的参数

更糟糕的是，对于 GBDT 类模型，不知道选取多少棵树作为最终模型

此外，多模型（请注意，k-fold 交叉验证在比赛中常常被称为单模型， 但是它实际上是多模型），往往会比单模型更稳定。



更复杂的建模方法 

在（传统的）数据科学竞赛当中，通常会采用更复杂的模型平均策略

很常见的一种策略是：以一个模型为基础，每次增加一个（通常都是数学形式不同的模型）

这样做的好处是可以不扔掉之前模型的效果



## AdaBoost 和残差学习

AdaBoost(Chengsheng, Huacheng, and Bing 2017) 的核心思想是训练两个模型，得到一个模型的预测之后，对于该模型预测较差的部分应该对之增加权重，而已经较好的部分则不需要特别的处理。 

这种方法和类似衍生方法在 2010 年左右十分火热 ，目前该方法基本已经被 GBDT 及相关模型所取代 

但是，**GBDT 类模型 + 神经网络 +AdaBoost **在很多实践当中效果很好



## 多模型建模和单模型建模的技术方案选择 

三种方式： 

​	1.唯一的一个模型 

​	2.同样模型的 k-fold（在竞赛中也叫单模型） 

​	3.多个模型的复杂集成 

一般来说，需要考虑的是算力要求 。

通常来讲，在算力可以达到的时候，尽可能不要用单模型 

传统认为单模型（尤其是线性回归和逻辑回归）比复杂模型更稳定， 因为表现形式简单，这主要原因是在实践中，他们往往对比的不是做过 k-fold 之后的模型。

其他所谓可解释性的问题往往不是真正限制模型应用的，尤其是 SHAP 值出现之后。相对来说，很多时候这里出现的是 “但求无过，不求有功” 的心态。



是否选好变量就可以用很简单的模型？

一些所谓业务专家吹嘘自己因为懂业务，所以只要自己随便懵出来的模型，就可以比这些复杂的方法预测性更好。

这是不可能的：

没有任何一个业务专家可以在 Kaggle 上一次就凭借自己的经验，用逻辑回归得到 Kaggle 第一名，甚至我怀疑有任何业务专家能够一次性根据自己的经验进入到前 90% 

核心问题在于数据和业务真实之间的关系是非常复杂的。大部分专家 的经验只对非常小的样本、非常少的变量和非常粗略的关系管用，但对于挖掘出来的数据的作用其实是很小的。

例如违约预测问题，可以问专家： 

​		1.是否可以告诉我从收入区间每 50 元钱之间违约概率有什么不同？ 

​		2.给定某用户三年内所有微信、支付宝银行卡等转账数据，是否可以告诉我哪些和收入有交叉效应？ 

结论：对于号称自己有业务专家支持的，应该引导做公平 POC。大部分专家预测结果，远远不如实习生乱做出来的模型效果好



模型的可解释性问题

正如前文所说：理论上好模型的可解释性和预测精度往往应该是相辅相成的

但是实际上，对于常见的所谓可解释的模型，其结果往往是互相矛盾的

原因在于常见的可解释模型，数学形式较为简单，但是带来的问题是， 这些模型所得到的估计偏差较大。所以虽然可 “解释”，但是解释出来的 结果是错的 

在 SHAP 值出现之后，我们发现如果从更复杂的模型中提取出真实的表 现，实际比逻辑回归和线性回归对业务的解释更直观



模型的鲁棒性

鲁棒性是指模型在不同（来源）的数据集上表现应该尽可能一致

鲁棒性从原则上来说是没有办法根本解决的

但是一些方法可以提升模型的鲁棒性： 

​		采用多种形式的模型进行平均 

​		小心进行数据预处理（删除掉过小的类别，对一些取值范畴进行限制等）



## 决策树模型

决策树的优点 

很好的捕捉**非线性效应**和**交叉效应**

可解释性

贪婪算法使得收敛保证和计算快捷



决策树的缺点

准确率很差，并且难以提高 → 主要原因在于模型表现力不够。

树的结构十分随机

各种调整参数的方法对于决策树的用处都不大 

一般仅仅用于变量的离散化，实际上效果也不如其他模型（例如 LightGBM）



随机森林和 ExtraTrees （Extremely  randomized trees，极端随机树）

核心思想：随机抽取部分变量和/或观测，分别拟合决策树 

最终预测结果由投票决定 

一般只支持离散或连续的预测值 

通常为了保证速度，采用对 X 分箱后再寻找合适的节点（据说可以防止 过拟合？） 

一个重要的变种为 ExtraTrees(Geurts, Ernst, and Wehenkel 2006)，核心思路在于随机抽取分割点，然后再从分割点选取合适的。



随机森林类算法的优缺点 

优点：表现力远远强于单颗决策树，且可以很容易实现并行 

缺点：树和树之间没有关联，通常根据一般情况定义一般的损失函数不是十分容易的。



GBDT 及相关系列 

相对于决策树来说，GBDT(Friedman 2001) 是一系列针对一般建模情况的算法。

核心思想：根据上一轮的运算结果对模型进行补充。



GBDT 核心算法

![image-20210208152203296](C:\Users\zhangqing\AppData\Roaming\Typora\typora-user-images\image-20210208152203296.png)

虽然 GBDT 的文章出现较早，但是实际上刚开始并没有那么流行，这多少和 GBDT 消耗算力较大（在当时看来）有关 

GDBT 引入到公众视角是从使用 GBDT+LR 的方式做点击率预估开始的 目前在 GBDT 的基础上，主要有四个比较著名的提升： 

XGBoost(Chen and Guestrin 2016) 

https://xgboost.readthedocs.io/en/latest/tutorials/model.html

LightGBM(Ke et al. 2017) 

CatBoost(Prokhorenkova et al. 2017) 

NODE(Popov, Morozov, and Babenko 2019) NODE 将会在神经网络建模中讲解



代码实现总体准则 

XGBoost、LightGBM 和 CatBoost 在代码实现上极其相像，所以只需要看懂其中一个包，就可以基本看懂这几个包 

此外，sklearn 当中的随机森林和 ExtraTrees 的实现并不好，不如采用 LightGBM 

我们以 LightGBM 为例来说明整体的方法，LightGBM比XGBoost实现效果要好。



重要的参数类：涉及到树的复杂度 

在 LightGBM 当中，**最主要的参数为 num_leaves（叶子个数）**

除此之外，一些方法还提供树的深度作为控制 

一般来说用叶子个数控制要比用深度控制更细腻，也更有助于选择优质 变量 

注意：叶子数量跟学习率高度相关

​			一般来说，**当树更复杂的时候，学习率要尽量减小**

​			尽可能控制在学习率可以增加较合理范畴达到最好



重要的参数类：涉及到数据筛选的随机性 

每一次随机选取多少变量或观测来拟合 

在 LightGBM 当中，这个参数称之为 bagging_fraction 以及 feature_fraction 

通常来说，从 0.8开始



Dart 

Dart(Vinayak and Gilad-Bachrach 2015) 是一种模仿 Dropout 方式来构建模型以防止过拟合的方法 

核心思想：在每次 boosting 的时候都将前一轮的一些树随机扔掉 

一般来说，这会极大减慢模型拟合的过程，但是在一些情况下可以得到更好的结果



其他参数 

类似于 LightGBM 的库有上百个不同的参数，这些参数的效果很难通过经验总结出来 

在一些官方网站当中，有关于调参的建议 

在一些情况下，则只能依靠一些经验积累，但任何人的经验积累都可能 是有问题的



如何寻找最优参数

当参数量非常大的时候，依靠遍历的方法去寻找最优的参数显然是有问题的 

一般来说，参数寻找放在三个阶段中： 

​		随机探索阶段 

​		顺序搜索阶段 

​		贝叶斯优化阶段



超参数搜索中如何做到公平客观

在我们最开始做任何超参数选择的时候，一定要考虑选择是否公平客观 

如果我们选择不同的变量，采用不同程度的调参（一个精调另外一个细调),那么得到的结果就会是不公平的，这并不能告诉我们衍生变量的好坏情况 

同样道理，对于不同的数据集，我们也不应该用不公平的比较法



随机探索阶段

随机探索阶段：尽可能多的收集关于模型运行的信息，并从中找到能够提示模型性质的线索

核心：尽可能多记录不同的 metric 

可以尝试一些极端的方法 

可以检查变量的重要性



顺序搜索阶段 

在确定了大致合理的参数范围后，我们可以开始按照参数的重要性进行搜索 

例如：首先调整学习率 + 深度，再调整 bagging_fraction 和 feature_fraction 

目的：为了找到一个大致合理的范畴，减少之后搜索的负责度



Hyperopt：

是进行超参数优化的一个类库。往往能够在相对较短的时间内获取原优于手动调参的最终结果。

一般而言，使用hyperopt的方式的过程可以总结为：

- 用于最小化的目标函数
- 搜索空间
- 存储搜索过程中所有点组合以及效果的方法
- 要使用的搜索算法

整体来说，Hyperopt 是基于贝叶斯方法的一套优化方法 

建议： 

​		在已经调过的最优参数周围进行调参，而未调过的参数则尽可能选择较大的范畴 

​		采用多次初始化要比采用一次初始化跑多次的效果更好 

​		Hyperopt 花费时间极长，尽量考虑是否一定需要采用这种方式



单模型和多模型

通常来说，调参至少要采用 k-fold 选取并在测试集上验证

如果要采用更复杂的模型集成方式，则最好构建 pipeline，并在每晚下班后自动调整接着在第二天早上查看最终结果



## 线性模型

“线性”模型的含义

我们这里所说的线性模型指的是有 x t iβ 这种形式的模型，其中 xi 为第 i 个样本的输入，而 β 则代表估计参数

线性模型的表达形式要比树模型复杂的多，所以相对来说，如果线性模型能找到合适的样本，则更容易保证在较小的模型中得到更好的效果。

反过来，由于线性模型的拟合不是贪婪的拟合，所以用线性模型处理高维的数据是很容易过拟合的

由于线性模型的表达式和树模型的不同，所以线性模型的特征构造有很多技巧

此外，由于线性模型对于异常值非常敏感，需要重点关注，也建议进行标准化



线性回归和逻辑回归

**线性回归针对的是目标为连续且可以取全部实数值的情况  **

在一些情况下，可以不用这样取值，比如收入一般不会是负 100 万的 

在这种情况下，我们要对模型做一些变化，例如取 log。 

逻辑回归也是类似的情况

此外还有一类模型叫做 GLM，可见 Andrew NG 讲义。



SVM：见 Andrew NG 讲义**[ 证明背下来 ]**



KNN：

KNN 的思路非常简单：假如我们需要处理的是分类问题，那么只需要找到距离最近的几个观测，然后看他们的分布情况即可

KNN 最大的问题：计算缓慢，而且推测也很慢 

KNN 一般很少单独使用，但是 KNN 的使用技巧中有一个很有用的方法



降维方法 

两种最常见的降维方法: 主成分方法和 t-SNE(Maaten and Hinton 2008) 

主成分法的主要目的是找到线性独立的、可以解释 X 变量的降维变量（不关心y）。

t-SNE 则更为复杂，需要通过梯度迭代来解决，并且效率比较低



t-SNE 和 KNN 的结合

在一些情况下，在控制学习率的同时，调整树的深度 

这在模型平均中是一个很重要的方法



## 模型评估指标

即使是分类和回归问题，也有很多指标，见sklearn 评估指标表格 

一般来说，最简单的指标最适合评估模型的效果（例如准确度） 

更复杂的指标，容易帮我们找到模型的一些问题。



关于 ROC 的注意事项

请注意，ROC 是一个很危险的指标

ROC 的基本思路：随着阈值的不同，正负样本区分不同，所以说应该考察在不同截断阈值下面的表现。

Q：大部分模型并不能对这个违约概率进行预测，在这种情况下可以做到 ROC 很高但是实际预测效果极差

一般方法：使用逻辑回归作为 Stacking 的最后一层
